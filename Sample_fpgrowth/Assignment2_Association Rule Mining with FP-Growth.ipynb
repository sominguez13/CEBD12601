{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Association Rule Mining with FP-Growth** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be identifying frequent itemsets using the FP-Growth Algorithm in Pyspark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we must import the appropriate libraries from Pyspark machine learning algorithms for frequent pattern matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the [Frequent Pattern Matching API documentation](https://spark.apache.org/docs/2.2.0/mllib-frequent-pattern-mining.html),\"The FP-growth algorithm is described in the paper Han et al., Mining frequent patterns without candidate generation, where “FP” stands for frequent pattern. Given a dataset of transactions, the first step of FP-growth is to calculate item frequencies and identify frequent items.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to [Spark documentation](https://spark.apache.org/docs/2.0.2/api/java/org/apache/spark/SparkContext.html) A SparkContext represents the connection to a Spark cluster, and can be used to create RDDs, accumulators and broadcast variables on that cluster. **Only one SparkContext may be active per JVM**. You must stop() the active SparkContext before creating a new one. This limitation may eventually be removed; see SPARK-2243 for more details.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.fpm import FPGrowth\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we first read in a text file (sample_fpgrowth.txt) with the transactiond data we will be using for association rule mining. Every line in the dataset corresponds to a transaction or basket and items are seperated by a space:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r z h k p\n",
    "z y x w v u t s\n",
    "s x o n r\n",
    "x z y m t s q e\n",
    "z\n",
    "x z y r q t p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first transaction, for example, contains the items r, z, h, k, and p."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we map data into an appropriate data strcuture and assigning this to a variable called transactions. .strip() returns a copy of the string in which all chars have been stripped from the beginning and the end of the string (default whitespace characters). .split(' ') returns a list of all the words in the string, using ' ' as the separator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sc.textFile(\"sample_fpgrowth.txt\")\n",
    "transactions = data.map(lambda line: line.strip().split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the transactions data to train an FP Growth model to identify frequent itemsets and association rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the [FP-growth documentation](https://spark.apache.org/docs/2.2.0/mllib-frequent-pattern-mining.html): spark.mllib’s FP-growth implementation takes the following (hyper-)parameters:\n",
    "\n",
    "* minSupport: the minimum support for an itemset to be identified as frequent. For example, if an item appears 3 out of 5 transactions, it has a support of 3/5=0.6.\n",
    "\n",
    "* numPartitions: the number of partitions used to distribute the work.\n",
    "\n",
    "After training the model, we extract freuqent itemsets and assign them to a dictionary where we can more easily keep track of their frequency. This will be helpful for determining association rules and relevant support and confidence metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = FPGrowth.train(transactions, minSupport = 0.2, numPartitions = 10)\n",
    "freqItemsets = model.freqItemsets().collect()\n",
    "\n",
    "freqItemsetsDict = {}\n",
    "\n",
    "for i in range(0, len(freqItemsets)):\n",
    "    freqItemsetsDict[str(freqItemsets[i].items)] = freqItemsets[i].freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we set a minimum confidence, generate association rules from the frequent itemsets identified above, and print rules with corresponding evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t', 's', 'y'] => ['x'] (support: 0.33 confidence: 1.00)\n",
      "['t', 's', 'y'] => ['z'] (support: 0.33 confidence: 1.00)\n",
      "['y', 'x', 'z'] => ['t'] (support: 0.33 confidence: 1.00)\n",
      "['y'] => ['x'] (support: 0.50 confidence: 1.00)\n",
      "['y'] => ['z'] (support: 0.50 confidence: 1.00)\n",
      "['y'] => ['t'] (support: 0.50 confidence: 1.00)\n",
      "['p'] => ['r'] (support: 0.33 confidence: 1.00)\n",
      "['p'] => ['z'] (support: 0.33 confidence: 1.00)\n",
      "['q', 't', 'z'] => ['y'] (support: 0.33 confidence: 1.00)\n",
      "['q', 't', 'z'] => ['x'] (support: 0.33 confidence: 1.00)\n",
      "['q', 'y'] => ['x'] (support: 0.33 confidence: 1.00)\n",
      "['q', 'y'] => ['z'] (support: 0.33 confidence: 1.00)\n",
      "['q', 'y'] => ['t'] (support: 0.33 confidence: 1.00)\n",
      "['t', 's', 'x'] => ['y'] (support: 0.33 confidence: 1.00)\n",
      "['t', 's', 'x'] => ['z'] (support: 0.33 confidence: 1.00)\n",
      "['q', 't', 'y', 'z'] => ['x'] (support: 0.33 confidence: 1.00)\n",
      "['q', 't', 'x', 'z'] => ['y'] (support: 0.33 confidence: 1.00)\n",
      "['q', 'x'] => ['y'] (support: 0.33 confidence: 1.00)\n",
      "['q', 'x'] => ['t'] (support: 0.33 confidence: 1.00)\n",
      "['q', 'x'] => ['z'] (support: 0.33 confidence: 1.00)\n",
      "['t', 'x', 'z'] => ['y'] (support: 0.33 confidence: 1.00)\n",
      "['x', 'z'] => ['y'] (support: 0.33 confidence: 1.00)\n",
      "['x', 'z'] => ['t'] (support: 0.33 confidence: 1.00)\n",
      "['p', 'z'] => ['r'] (support: 0.33 confidence: 1.00)\n",
      "['t'] => ['y'] (support: 0.50 confidence: 1.00)\n",
      "['t'] => ['x'] (support: 0.50 confidence: 1.00)\n",
      "['t'] => ['z'] (support: 0.50 confidence: 1.00)\n",
      "['y', 'z'] => ['x'] (support: 0.50 confidence: 1.00)\n",
      "['y', 'z'] => ['t'] (support: 0.50 confidence: 1.00)\n",
      "['p', 'r'] => ['z'] (support: 0.33 confidence: 1.00)\n",
      "['t', 's'] => ['y'] (support: 0.33 confidence: 1.00)\n",
      "['t', 's'] => ['x'] (support: 0.33 confidence: 1.00)\n",
      "['t', 's'] => ['z'] (support: 0.33 confidence: 1.00)\n",
      "['q', 'z'] => ['y'] (support: 0.33 confidence: 1.00)\n",
      "['q', 'z'] => ['t'] (support: 0.33 confidence: 1.00)\n",
      "['q', 'z'] => ['x'] (support: 0.33 confidence: 1.00)\n",
      "['q', 'y', 'z'] => ['x'] (support: 0.33 confidence: 1.00)\n",
      "['q', 'y', 'z'] => ['t'] (support: 0.33 confidence: 1.00)\n",
      "['y', 'x'] => ['z'] (support: 0.50 confidence: 1.00)\n",
      "['y', 'x'] => ['t'] (support: 0.50 confidence: 1.00)\n",
      "['q', 'x', 'z'] => ['y'] (support: 0.50 confidence: 1.00)\n",
      "['q', 'x', 'z'] => ['t'] (support: 0.50 confidence: 1.00)\n",
      "['t', 'y', 'z'] => ['x'] (support: 0.50 confidence: 1.00)\n",
      "['q', 'y', 'x'] => ['z'] (support: 0.33 confidence: 1.00)\n",
      "['q', 'y', 'x'] => ['t'] (support: 0.33 confidence: 1.00)\n",
      "['q', 't', 'y', 'x'] => ['z'] (support: 0.33 confidence: 1.00)\n",
      "['t', 's', 'x', 'z'] => ['y'] (support: 0.33 confidence: 1.00)\n",
      "['s', 'y', 'x'] => ['z'] (support: 0.33 confidence: 1.00)\n",
      "['s', 'y', 'x'] => ['t'] (support: 0.33 confidence: 1.00)\n",
      "['s', 'x', 'z'] => ['y'] (support: 0.33 confidence: 1.00)\n",
      "['s', 'x', 'z'] => ['t'] (support: 0.33 confidence: 1.00)\n",
      "['q', 'y', 'x', 'z'] => ['t'] (support: 0.33 confidence: 1.00)\n",
      "['s', 'y'] => ['x'] (support: 0.33 confidence: 1.00)\n",
      "['s', 'y'] => ['z'] (support: 0.33 confidence: 1.00)\n",
      "['s', 'y'] => ['t'] (support: 0.33 confidence: 1.00)\n",
      "['q', 't', 'y'] => ['x'] (support: 0.33 confidence: 1.00)\n",
      "['q', 't', 'y'] => ['z'] (support: 0.33 confidence: 1.00)\n",
      "['t', 'y'] => ['x'] (support: 0.50 confidence: 1.00)\n",
      "['t', 'y'] => ['z'] (support: 0.50 confidence: 1.00)\n",
      "['t', 'z'] => ['y'] (support: 0.50 confidence: 1.00)\n",
      "['t', 'z'] => ['x'] (support: 0.50 confidence: 1.00)\n",
      "['t', 's', 'y', 'x'] => ['z'] (support: 0.33 confidence: 1.00)\n",
      "['t', 'y', 'x'] => ['z'] (support: 0.50 confidence: 1.00)\n",
      "['q', 't'] => ['y'] (support: 0.33 confidence: 1.00)\n",
      "['q', 't'] => ['x'] (support: 0.33 confidence: 1.00)\n",
      "['q', 't'] => ['z'] (support: 0.33 confidence: 1.00)\n",
      "['q'] => ['y'] (support: 0.33 confidence: 1.00)\n",
      "['q'] => ['t'] (support: 0.33 confidence: 1.00)\n",
      "['q'] => ['x'] (support: 0.33 confidence: 1.00)\n",
      "['q'] => ['z'] (support: 0.33 confidence: 1.00)\n",
      "['t', 's', 'z'] => ['y'] (support: 0.33 confidence: 1.00)\n",
      "['t', 's', 'z'] => ['x'] (support: 0.33 confidence: 1.00)\n",
      "['t', 'x'] => ['y'] (support: 0.33 confidence: 1.00)\n",
      "['t', 'x'] => ['z'] (support: 0.50 confidence: 1.00)\n",
      "['s', 'z'] => ['y'] (support: 0.50 confidence: 1.00)\n",
      "['s', 'z'] => ['x'] (support: 0.50 confidence: 1.00)\n",
      "['s', 'z'] => ['t'] (support: 0.50 confidence: 1.00)\n",
      "['s', 'y', 'x', 'z'] => ['t'] (support: 0.50 confidence: 1.00)\n",
      "['s'] => ['x'] (support: 0.50 confidence: 1.00)\n",
      "['t', 's', 'y', 'z'] => ['x'] (support: 0.50 confidence: 1.00)\n",
      "['s', 'y', 'z'] => ['x'] (support: 0.50 confidence: 1.00)\n",
      "['s', 'y', 'z'] => ['t'] (support: 0.50 confidence: 1.00)\n",
      "['q', 't', 'x'] => ['y'] (support: 0.50 confidence: 1.00)\n",
      "['q', 't', 'x'] => ['z'] (support: 0.33 confidence: 1.00)\n",
      "['r', 'z'] => ['p'] (support: 0.33 confidence: 1.00)\n",
      "['x'] => ['z'] (support: 0.50 confidence: 0.75)\n",
      "['x'] => ['y'] (support: 0.50 confidence: 0.75)\n",
      "['x'] => ['s'] (support: 0.50 confidence: 0.75)\n",
      "['x'] => ['t'] (support: 0.50 confidence: 0.75)\n",
      "['y', 'x', 'z'] => ['s'] (support: 0.50 confidence: 0.67)\n",
      "['y', 'x', 'z'] => ['q'] (support: 0.50 confidence: 0.67)\n",
      "['y'] => ['s'] (support: 0.50 confidence: 0.67)\n",
      "['y'] => ['q'] (support: 0.50 confidence: 0.67)\n",
      "['t', 'x', 'z'] => ['s'] (support: 0.50 confidence: 0.67)\n",
      "['t', 'x', 'z'] => ['q'] (support: 0.50 confidence: 0.67)\n",
      "['x', 'z'] => ['s'] (support: 0.50 confidence: 0.67)\n",
      "['x', 'z'] => ['q'] (support: 0.50 confidence: 0.67)\n",
      "['t'] => ['s'] (support: 0.33 confidence: 0.67)\n",
      "['t'] => ['q'] (support: 0.33 confidence: 0.67)\n",
      "['y', 'z'] => ['s'] (support: 0.33 confidence: 0.67)\n",
      "['y', 'z'] => ['q'] (support: 0.33 confidence: 0.67)\n",
      "['y', 'x'] => ['s'] (support: 0.33 confidence: 0.67)\n",
      "['y', 'x'] => ['q'] (support: 0.33 confidence: 0.67)\n",
      "['t', 'y', 'z'] => ['s'] (support: 0.33 confidence: 0.67)\n",
      "['t', 'y', 'z'] => ['q'] (support: 0.33 confidence: 0.67)\n",
      "['t', 'y'] => ['s'] (support: 0.33 confidence: 0.67)\n",
      "['t', 'y'] => ['q'] (support: 0.33 confidence: 0.67)\n",
      "['t', 'z'] => ['s'] (support: 0.33 confidence: 0.67)\n",
      "['t', 'z'] => ['q'] (support: 0.33 confidence: 0.67)\n",
      "['r'] => ['x'] (support: 0.33 confidence: 0.67)\n",
      "['r'] => ['z'] (support: 0.33 confidence: 0.67)\n",
      "['r'] => ['p'] (support: 0.33 confidence: 0.67)\n",
      "['t', 'y', 'x'] => ['s'] (support: 0.33 confidence: 0.67)\n",
      "['t', 'y', 'x'] => ['q'] (support: 0.33 confidence: 0.67)\n",
      "['t', 'x'] => ['s'] (support: 0.33 confidence: 0.67)\n",
      "['t', 'x'] => ['q'] (support: 0.33 confidence: 0.67)\n",
      "['t', 'y', 'x', 'z'] => ['s'] (support: 0.33 confidence: 0.67)\n",
      "['t', 'y', 'x', 'z'] => ['q'] (support: 0.33 confidence: 0.67)\n",
      "['s'] => ['y'] (support: 0.33 confidence: 0.67)\n",
      "['s'] => ['z'] (support: 0.33 confidence: 0.67)\n",
      "['s'] => ['t'] (support: 0.33 confidence: 0.67)\n",
      "['s', 'x'] => ['y'] (support: 0.33 confidence: 0.67)\n",
      "['s', 'x'] => ['z'] (support: 0.33 confidence: 0.67)\n",
      "['s', 'x'] => ['t'] (support: 0.33 confidence: 0.67)\n",
      "['z'] => ['x'] (support: 0.33 confidence: 0.60)\n",
      "['z'] => ['y'] (support: 0.33 confidence: 0.60)\n",
      "['z'] => ['t'] (support: 0.33 confidence: 0.60)\n"
     ]
    }
   ],
   "source": [
    "minConfidence = .6\n",
    "rules = sorted(model._java_model.generateAssociationRules(minConfidence).collect(), \n",
    "    key=lambda x: x.confidence(), reverse=True)\n",
    "\n",
    "for j in range(0, len(rules)):\n",
    "    antecedent = list(rules[j].antecedent())\n",
    "    consequent = list(rules[j].consequent())\n",
    "    ruleItemset = str(antecedent + consequent)\n",
    "    \n",
    "    try:\n",
    "        support = \"{0:.2f}\".format(freqItemsetsDict[ruleItemset] / transactions.count())\n",
    "    except KeyError:\n",
    "        next\n",
    "    \n",
    "    confidence = \"{0:.2f}\".format(rules[j].confidence())\n",
    "    \n",
    "    try:\n",
    "        print(antecedent, '=>', consequent, '(support: '+ str(support), 'confidence: '+ str(confidence) + ')')\n",
    "    except NameError:\n",
    "        next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interpret these association rules as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['t', 'y', 'z'] => ['x'] (support: 0.50 confidence: 1.00)\n",
    "\n",
    "* A support of .50 suggests that products t, y, z, and x appear together in 50% of the transactions.\n",
    "\n",
    "* A confidence of 1 suggests that every transaction that contains products t, y, and z also contains product x.\n",
    "\n",
    "['z'] => ['x'] (support: 0.33 confidence: 0.60)\n",
    "\n",
    "* A support of .33 suggests that products z and x appear together in 33% of the transactions.\n",
    "\n",
    "* A confidence of .6 suggests that every 100 transactions that contains product z, 60 also contains product x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
